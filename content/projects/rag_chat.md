+++
title = 'ğŸ’¬streamlitê³¼ RAGë¥¼ í™œìš©í•œ ì±—ë´‡'
date = 2025-08-08T11:00:50+09:00
draft = false
categories = []
+++

ìš”ìƒˆ RAGì— ë¹ ì ¸ì„œ ì¬ë°Œê²Œ ê³µë¶€ ì¤‘ì´ë‹¤.  
ë°°ìš´ ë‚´ìš©ì„ ì‹¤ìŠµí•˜ê¸° ìœ„í•´ ë‚˜ë§Œì˜ Agentë¥¼ í•˜ë‚˜ ë§Œë“¤ì–´ ë´¤ë‹¤. (ë¬¼ë¡  êµì¬ ì°¸ê³ í•´ì„œ)  

## ê°œìš”
streamlitì„ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œê¸°ë°˜ ì§ˆì˜ì‘ë‹µ RAG ì‹œìŠ¤í…œ.   
ì‚¬ìš©ìê°€ ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ë©´ ë‚´ìš©ì„ Embedding í•œ í›„ ì‚¬ìš©ìì˜ ì§ˆì˜ì— ì‘ë‹µí•˜ëŠ” ì±—ë´‡.

1. í™˜ê²½: Python 3.12 / FAISS ë¼ì´ë¸ŒëŸ¬ë¦¬ / Streamlit ë¼ì´ë¸ŒëŸ¬ë¦¬
2. ëª¨ë¸: gpt-4
3. GtiHub url : [https://github.com/Solxcero/Lang/blob/main/pdfChatApp2.py](https://github.com/Solxcero/Lang/blob/main/pdfChatApp2.py)

## ê³¼ì •
### Library
ì‚¬ìš©í•˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì€ ì•„ë˜ê³¼ ê°™ë‹¤.

```python
from dotenv import load_dotenv
from langchain_community.chat_models import ChatOpenAI              
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import OpenAIEmbeddings
from langchain.text_splitter import CharacterTextSplitter
from langchain.schema import ChatMessage, HumanMessage, SystemMessage
from langchain.callbacks.base  import BaseCallbackHandler
from pdfminer.high_level import extract_text
import streamlit as st
import os
```
ì£¼ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ëª…   
1. ChatOpenAI : OpenAIì˜ GPT ëª¨ë¸ì„ ì´ìš”í•´ ëŒ€í™”ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬. ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•˜ê¸° ìœ„í•´ GPT-4 ëª¨ë¸ì„ í˜¸ì¶œí•˜ëŠ” ë° ì‚¬ìš©.
2. FAISS :  ë²¡í„°DBë¼ì´ë¸ŒëŸ¬ë¦¬. ì„ë² ë”©ëœ ë²¡í„°ë¥¼ ì €ì¥í•˜ëŠ” DBë¥¼ ì œê³µí•´ì£¼ëŠ” íŒŒì´ì¬ ìì²´ ë¼ì´ë¸ŒëŸ¬ë¦¬
3. OpenAIEmbeddings : OpenAIì˜ ì„ë² ë”©(ë²¡í„°í™”)ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬. ë¬¸ì„œë¥¼ ë²¡í„°í™”í•˜ì—¬ ìœ ì‚¬ì„± ê²€ìƒ‰ ì§€ì›. ì´ë²ˆ í”„ë¡œì íŠ¸ì—ì„œëŠ” ë‹¤êµ­ì–´ ì„±ëŠ¥ì´ ì¢‹ì€ text-embedding-3-largeë¥¼ ì‚¬ìš©(but ë¹„ì‹¸ê² ì£ )
4. CharacterTextSplitter : ê¸´ ë¬¸ì„œë¥¼ ì‘ì€ ì²­í¬ë¡œ ë‚˜ëˆ„ëŠ” ë° ì‚¬ìš©ë˜ëŠ” ìœ í‹¸ë¦¬í‹°. 
5. ChatMessage, HumanMessage, SystemMessage :  ëŒ€í™”í˜• AI ëª¨ë¸ì—ì„œ ì‚¬ìš©í•  ë©”ì‹œì§€ ìœ í˜•ì„ ì •ì˜í•˜ëŠ” ìŠ¤í‚¤ë§ˆ. ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ GPT ëª¨ë¸ë¡œ ì „ë‹¬í•˜ê¸° ìœ„í•´ ì‚¬ìš©.
6. BaseCallbackHandler :  GPT ëª¨ë¸ì˜ ì‘ë‹µì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•˜ëŠ” ì½œë°± í•¸ë“¤ëŸ¬ë¥¼ ì •ì˜í•˜ëŠ” í´ë˜ìŠ¤. GPT ëª¨ë¸ì—ì„œ ìƒì„±ëœ í† í°ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ web UIì— í‘œì‹œí•˜ê¸° ìœ„í•´ ì‚¬ìš©. 
7. extract_text : PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” ê³ ìˆ˜ì¤€ API. 

### MarkDownStreamHandler
Streamlit ë§ˆí¬ë‹¤ìš´ ì»¨í…Œì´ë„ˆì— ìƒì„±ëœ í† í°ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë°í•˜ëŠ” ì‚¬ìš©ì ì •ì˜ í•¸ë“¤ëŸ¬
```python
class MarkdownStreamHandler(BaseCallbackHandler):

    def __init__(self, output_container, initial_content=""):
        self.output_container = output_container 
        self.generated_content = initial_content  

    def on_llm_new_token(self, token: str, **kwargs) -> None:
        self.generated_content += token
        self.output_container.markdown(self.generated_content)
```
- BaseCallbackHandler : íŠ¹ì • ì´ë²¤íŠ¸ ë°œìƒ ì‹œ í˜¸ì¶œë˜ëŠ” ì½œë°± ë©”ì„œë“œ(on_llm_new_token ë“±)ë¥¼ ì œê³µí•˜ëŠ” í•¸ë“¤ëŸ¬. ì£¼ë¡œ LLMê³¼ ê°™ì€ ì‹œìŠ¤í…œê³¼ ìƒí˜¸ì‘ìš©í•¨. ë¶€ëª¨í´ë˜ìŠ¤ì—ì„œ ì œê³µí•˜ëŠ” ë©”ì„œë“œë¥¼ ì˜¤ë²„ë¼ì´ë“œí•˜ì—¬ íŠ¹ì • ë™ì‘(ì—¬ê¸°ì„œëŠ” ë§ˆí¬ë‹¤ìš´ìŠ¤íŠ¸ë¦¬ë°)ì„ êµ¬í˜„   

- output_container : ë§ˆí¬ë‹¤ìš´ í‘œì‹œí•  ëŒ€ìƒ
- initial_content : ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘ ì‹œ ì´ˆê¸°í™”ëœ ìƒíƒœì˜ í…ìŠ¤íŠ¸
- self.output_container : ì™¸ë¶€ì—ì„œ ì „ë‹¬ë„ë‹ˆ ì¶œë ¥ ì»¨í…Œì´ë„ˆ ê°ì²´ë¥¼ ì €ì¥
- self.generated_content : ëˆ„ì ëœ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì €ì¥

- on_llm_new_token ë©”ì„œë“œ : ìƒˆë¡œìš´ í† í°ì´ ìƒì„±ë  ë•Œë§ˆë‹¤ í˜¸ì¶œë˜ë©°, ìƒì„±ë„ë‹ˆ í† í°ì„ generated_contentì— ì¶”ê°€

### PDF ì²˜ë¦¬ í•¨ìˆ˜
```python
def extract_text_from_pdf(file):
    '''pdfminerë¥¼ ì‚¬ìš©í•˜ì—¬ PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ.'''
    try:
        return extract_text(file)
    except Exception as error:
        st.error(f"PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {error}")
        return ""
    

def handle_uploaded_file(file):
    '''ì—…ë¡œë“œ ëœ PDF íŒŒì¼ì„ ì²˜ë¦¬í•˜ê³  ë²¡í„° ìŠ¤í† ì–´ ì¤€ë¹„'''
    if not file:
        return None, None
    
    # íŒŒì¼ ìœ í˜•ì— ë”°ë¼ í…ìŠ¤íŠ¸ ì¶”ì¶œ
    document_text = extract_text_from_pdf(file) if file.type == 'application/pdf' else ""
    if not document_text:
        st.error("í…ìŠ¤íŠ¸ ì¶”ì¶œ ë¶ˆê°€")
        return None, None
    
    # ë¬¸ì„œë¥¼ ì‘ì€ ì²­í¬ë¡œ ë‚˜ëˆ„ì–´ ë²¡í„°í™” ì¤€ë¹„
    text_splitter = CharacterTextSplitter(
        separator="\n",
        chunk_size=1000,
        chunk_overlap=200
    )

    document_chunks = text_splitter.create_documents([document_text])
    st.info(f"{len(document_chunks)} ê°œì˜ ë¬¸ì„œ ë‹¨ë½ ìƒì„±.")

    # ìœ ì‚¬ì„± ê²€ìƒ‰ì„ ìœ„í•œ ë²¡í„° ìŠ¤í† ì–´ ìƒì„±
    vectorstore = FAISS.from_documents(document_chunks, embedding_model)
    return vectorstore, document_text
```

### RAG ì‘ë‹µ ìƒì„± 
```python
def get_rag_response(user_query, vectorstore, callback_handler):
    '''ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ê¸°ë°”ëŠ¥ë¡œ ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ ì‘ë‹µ ìƒì„±'''
    if not vectorstore:
        st.error("No Vectorstore. Upload docs first.")
        return ""
    
    # ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œ 3ê°œ ê²€ìƒ‰
    retrieved_docs = vectorstore.similarity_search(user_query, k=3)
    retrieved_text = "\n".join(f"ë¬¸ì„œ {i+1} : {doc.page_content}" for i, doc in enumerate(retrieved_docs))

    # LLM ì„¤ì •
    chat_model = ChatOpenAI(model_name = "gpt-4", temperature=0, streaming=True, callbacks=[callback_handler])

    # RAG í”„ë¡¬í”„íŠ¸ 
    rag_prompt = [
        SystemMessage(content = "ì œê³µëœ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”. ì •ë³´ê°€ ì—†ìœ¼ë©´ 'ëª¨ë¥´ê² ìŠµë‹ˆë‹¤' ë¼ê³  ë‹µë³€í•˜ì„¸ìš”"),
        HumanMessage(content=f"ì§ˆë¬¸ : {user_query}\n\n{retrieved_text}")

    ]

    try:
        response = chat_model(rag_prompt)
        return response.content
    
    except Exception as error:
        st.error(f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {error}")
        return ""
```
- ìƒì„±ëœ ì‘ë‹µì˜ ì¼ê´€ì„±ì„ ë†’ì´ê¸° ìœ„í•´ temperatureë¥¼ 0ìœ¼ë¡œ ì„¤ì • (ììœ ë„ë¥¼ ë°°ì œí•œ ì´ì„±ì ì¸ ì‘ë‹µ)
- callbacks=[callback_handler] : ëª¨ë¸ì´ ì¶œë ¥ì´ ìƒì„±ë  ë•Œë§ˆë‹¤ callback_handlerë¥¼ í†µí•´ ì‹¤ì‹œê°„ìœ¼ë¡œ ì²˜ë¦¬ 

----
ìš”ë ‡ê²Œ ì£¼ìš” í•¨ìˆ˜ì´ë©°, streamlit UI ë° ì‚¬ìš©ì ì¿¼ë¦¬ ì²˜ë¦¬ì™€ ê°™ì€ ì „ì²´ ì†ŒìŠ¤ì½”ë“œëŠ” ê¹ƒí—ˆë¸Œì—ì„œ í™•ì¸í•  ìˆ˜ ìˆë‹¤.  
GtiHub url : [https://github.com/Solxcero/Lang/blob/main/pdfChatApp2.py](https://github.com/Solxcero/Lang/blob/main/pdfChatApp2.py)

## TEST
ë‚´ê°€ í…ŒìŠ¤íŠ¸í•  ë¬¸ì„œëŠ” 2021ë…„ì— í° ì´ìŠˆì˜€ë˜ ê²Œì„ìŠ¤íƒ‘ ì‚¬íƒœì— ëŒ€í•œ ë³´ê³ ìë£Œë¡œ, ê°œì¸ íˆ¬ììë“¤ì´ ê°€ì¥ ë§ì´ ì‚¬ìš©í–ˆë˜ ì¦ê¶Œê±°ë˜ ì•± 'ë¡œë¹ˆí›„ë“œ'ì— ëŒ€í•œ ë‚´ìš©ì´ ë‹´ê²¨ìˆë‹¤.  
(ê°œì¸ì ìœ¼ë¡œ ê²Œì„ìŠ¤íƒ‘ ì‚¬íƒœë¥¼ ë§¤ìš° í¥ë¯¸ë¡­ê²Œ ìƒê°í•¨.)
<p align="center">
  <a href="/images/projects/rag_chat/paper.png" data-lightbox="image-set">
    <img src="/images/projects/rag_chat/paper.png" alt="Your Alt Text" style="width: 450px;" >
  </a>
</p>

ì´ì œ Streamlitì„ ì‹¤í–‰í•´ë³´ì. `streamlit run app.py` ë¡œ ì‹¤í–‰í•˜ë©´ ëœë‹¤.

<p align="center">
  <a href="/images/projects/rag_chat/streamlit_1.png" data-lightbox="image-set">
    <img src="/images/projects/rag_chat/streamlit_1.png" alt="Your Alt Text"style="width: 450px;" >
  </a>
</p>

ìš”ë ‡ê²Œ ì•„ì£¼ ì‹¬í”Œí•œ UIê°€ ë‚˜íƒ€ë‚œë‹¤. ë‚´ê°€ ì›í•˜ëŠ” ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ë©´ ë¬¸ì„œ ë‹¨ë½ì´ ëª‡ê°œê°€ ìƒì„±ë˜ì—ˆëŠ”ì§€ í‘œì‹œí•´ì¤€ë‹¤. (ìƒì„± ì‹œê°„ì€ ë¬¸ì„œì˜ ê¸¸ì´ì— ë”°ë¼ ë‹¤ë¦„)

ì´ì œ ì§ˆë¬¸ì„ í•´ë³´ì. 
ë¬¸ì„œì™€ ê´€ë ¨ëœ ì§ˆë¬¸ í•˜ë‚˜ì™€ ê´€ë ¨ ì—†ëŠ” ì§ˆë¬¸ í•˜ë‚˜ë¥¼ í…ŒìŠ¤íŠ¸ í•´ë³´ê² ë‹¤. 
<p align="center">
  <a href="/images/projects/rag_chat/streamlit_2.png" data-lightbox="image-set">
    <img src="/images/projects/rag_chat/streamlit_2.png" alt="Your Alt Text" style="width: 450px;" >
  </a>
</p>

ë‚´ê°€ ë‹µë³€ì„ ê°„ê²°í•˜ê²Œ í•´ë‹¬ë¼ê³  ì¡°ê±´ì„ ê±¸ì–´ë’€ê¸°ì— ê¸¸ê²Œ ì„¤ëª…ì„ í•´ì£¼ì§„ ì•Šì•˜ë‹¤.  
ë¬¸ì„œì—ì„œ ë§í•˜ëŠ” ë§¤ìˆ˜ë²„íŠ¼ì„ ì—†ì•¤ ì´ìœ ëŠ” ë‚˜ë¦„ ì˜ ìš”ì•½í•´ì„œ ë‹µë³€í•œ ë“¯í•˜ë‹¤. (~~ì”¨íƒ€ë¸ ë•Œë¬¸ì´ì•¼ ì”¨íƒ€ë¸ ë•Œë¬¸ì´ì•¼~~) 

ê·¸ë¦¬ê³  ê¹€ì¹˜ì°Œê°œ ë ˆì‹œí”¼ëŠ” ëª¨ë¥¸ë‹¤ê³  ë‹µë³€ì„ ì˜ í•´ì£¼ì—ˆë‹¤. 

## ê²°ë¡ 
ì´ë ‡ê²Œ ë¬¸ì„œ ê¸°ë°˜ RAG ChatBotì„ ë§Œë“¤ì–´ë³´ì•˜ë‹¤.  
ë³µì¡í•œ êµ¬í˜„ ì—†ì´ ê°„ë‹¨í•œ ì½”ë“œì´ì§€ë§Œ, ê·¸ ë’¤ì— ìˆëŠ” ê¸°ìˆ ì€ ì „í˜€ ê°„ë‹¨í•˜ì§€ê°€ ì•Šë‹¤.  
OpenAIì˜ ê³ ê¸‰ LLM ê¸°ìˆ ì„ ë¹Œë ¤ì“°ëŠ” ê²ƒì´ê¸° ë•Œë¬¸ì— ê²°êµ­ ë‹¤ ë¹„ìš©ìœ¼ë¡œ ì§€ë¶ˆí•´ì•¼ í•œë‹¤.  

<p align="center">
  <a href="/images/projects/rag_chat/APIcost.png" data-lightbox="image-set">
    <img src="/images/projects/rag_chat/APIcost.png" alt="Your Alt Text" style="width: 300px;">
  </a>
</p>

ì´ë²ˆ í…ŒìŠ¤íŠ¸ì—ë§Œ ì‚¬ìš©ëœ í† í°ì´ë‹¤.  

ë¹„ìš© ì¸¡ë©´ì—ì„œëŠ” 'ì²­í‚¹', 'í”„ë¡¬í”„íŠ¸' ì „ëµì„ ì˜ êµ¬ì„±í•˜ëŠ” ê²Œ ì¤‘ìš”í•  ë“¯ í•˜ë‹¤. ë¬¼ë¡  ì„ë² ë”© ëª¨ë¸ë„ ìƒí™©ì— ë§ê²Œ ì˜ ì„ íƒí•´ì•¼ í•œë‹¤. 
ì´ ë¶€ë¶„ì— ëŒ€í•´ì„œëŠ” ë”°ë¡œ ì¡°ì‚¬ë¥¼ í•˜ê³  ìˆë‹¤. ê¸°íšŒê°€ ëœë‹¤ë©´ ë¸”ë¡œê·¸ì—ë„ ì •ë¦¬í•´ì„œ ì˜¬ë¦¬ë„ë¡ í•˜ê² ë‹¤.  


## Debug Log
1. Pydantic Error

    ```shell
    PydanticUserError: `OpenAI` is not fully defined; you should define `BaseCache`, then call `OpenAI.model_rebuild()`.
    ```
    pydantic ë²„ì „ì´ 2.11.0 ì´ìƒì´ ì„¤ì¹˜ëœ ê²½ìš°ì— langchain ëª¨ë“ˆê³¼ í˜¸í™˜ì´ ì•ˆë˜ëŠ” ë¬¸ì œê°€ ë°œìƒí•  ìˆ˜ ìˆìŒ. 

    í•´ê²° : ë²„ì „ ë§ì¶°ì£¼ê¸°
    ```shell
    pip install langchain-core==0.3.0 langchain-openai==0.2.0 pydantic==2.10.6
    ```

